{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Deep Learning Frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we go into deep learning modelling, we will first need to have a quick familiarisation with a deep learning framework. We recommend __[Keras](https://keras.io)__, which is built on top of Tensorflow, but alternatively, you can consider __[PyTorch](https://pytorch.org)__. Resources are abundant online on how to use them, but here are some official guides to get you started:\n",
    "- PyTorch has a [60 Minute Blitz Guide](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html)\n",
    "- Tensorflow has an [Intro to Keras guide](https://www.tensorflow.org/guide/keras)\n",
    "\n",
    "A few words on the difference between Keras and PyTorch - Keras is a high level wrapper on top of Google's Tensorflow, the most popular deep learning framework out there. Being more low level, Tensorflow faces many issues and troubles, which are addressed by the abstractions of Keras, making it a great way to start. Facebook's PyTorch on the other hand is a newcomer which has received massive interest in recent years, and is playing catch up to Tensorflow/Keras.\n",
    "\n",
    "If you are more interested in how deep learning software has evolved since the days of Caffe and Theano as well as more in depth into what is happening in the software behind the scenes, we also recommend a [full lecture from Stanford](https://www.youtube.com/watch?v=6SlgtELqOWc) on this topic, although this is extra knowledge that isn't fully critical to this week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base on the tutorials you go through, you should be ready to build a 2 (or more) layer Multi-Level Perceptron (MLP) with deep learning. With the dataset you have prepared your machine learning model in the previous section, run your data through a MLP model with `Dense` (`Linear`) layers instead. Do some slight model adjustments, and discuss what kind of adjustments lead to improvements in score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./cifar10/data_batch_1', 'rb') as fo:\n",
    "    batch1_dict = pickle.load(fo, encoding='bytes')\n",
    "X = batch1_dict[b'data']\n",
    "y = np.array(batch1_dict[b'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batches.meta data_batch_2 data_batch_4 readme.html\r\n",
      "data_batch_1 data_batch_3 data_batch_5 test_batch\r\n"
     ]
    }
   ],
   "source": [
    "!ls cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=magenta>\n",
    "1. transformations/preprocessing -> totensor, normalisation  <br />\n",
    "2. load it into a loader  \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./cifar10/test_batch', 'rb') as fo:\n",
    "    test_dict = pickle.load(fo, encoding='bytes')\n",
    "X_test = test_dict[b'data']\n",
    "y_test = np.array(test_dict[b'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nus/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages/ipykernel/__main__.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "X, y = torch.tensor(X).float(), torch.tensor(y).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nus/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages/ipykernel/__main__.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = torch.tensor(X_test).float(), torch.tensor(y_test).long()\n",
    "test_dataset = torch.utils.data.TensorDataset(X, y)\n",
    "cifar10_test = torch.utils.data.DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 3072])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.utils.data.TensorDataset(X, y)\n",
    "cifar10_data = torch.utils.data.DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = nn.Sequential(\n",
    "    nn.Linear(3072, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(mlp.parameters(), 0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "mlp.train()\n",
    "for data, label in cifar10_data:\n",
    "    cnt += 1\n",
    "    mlp.zero_grad()\n",
    "    pred = mlp(data)\n",
    "    loss = criterion(pred, label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if cnt % 500 == 0:\n",
    "        print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave loss: 2.3025026321411133, corrects: 1016\n"
     ]
    }
   ],
   "source": [
    "eval_mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_mlp():\n",
    "    mlp.eval()\n",
    "    total_loss = 0\n",
    "    cnt = 0\n",
    "    corrects = 0\n",
    "    for data, label in cifar10_test:\n",
    "        cnt += 1\n",
    "        pred = mlp(data)\n",
    "        loss = criterion(pred, label)\n",
    "        if torch.argmax(pred) == label.item():\n",
    "            corrects += 1\n",
    "        total_loss += loss\n",
    "    print('Ave loss: {}, corrects: {}'.format(total_loss/len(cifar10_test), corrects))\n",
    "    mlp.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=magenta>\n",
    "1. loss vs accuracy: for every epoch 1. training_loss, 2. val_loss 3. top1 acc <br />\n",
    "2. a. preprocess and load b. create architecture c. create training `train()` script d. evaluation `eval() -> val_loss, acc` scripts e. run altogether\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai-cpu]",
   "language": "python",
   "name": "conda-env-fastai-cpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
